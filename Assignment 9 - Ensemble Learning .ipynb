{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omarreess/DLI-Internship-Data-Science/blob/main/Assignment%209%20-%20Ensemble%20Learning%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FVeHI75fmIz"
      },
      "source": [
        "<H2><center> Ensemble Learning for Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2-wWj5ORv4o"
      },
      "source": [
        "We will try Most of Ensemble Trees to get most accurate one\n",
        "\n",
        "Then we'll try to improve it "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvo-kcxNFwM2"
      },
      "source": [
        "<H2> Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n-2eHIaFgxX"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from keras.datasets import mnist\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support \n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import sklearn\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, StackingClassifier ,RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJJbTsq3iWrO"
      },
      "source": [
        "<H2> Reshaping Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS1mrO_QF6mh",
        "outputId": "b2f45045-fe36-407b-b0f4-76447e1bc67f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0],-1) / 255.0 \n",
        "X_test = X_test.reshape(X_test.shape[0],-1) / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFWfjYrXin5e"
      },
      "source": [
        "<H2> Fitting Data with Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9lUG2bHGFd2",
        "outputId": "1d4dc822-7e2c-47e2-a52e-137e607cad98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Decision Tree using entropy criterion \n",
            "\n",
            "f1 score with micro method : 88.66% \n",
            "\n",
            "f1 score with macro method : 88.14% \n",
            "\n",
            "f1 score with weighted method : 88.66% \n",
            "\n",
            "Default Decision Tree using gini criterion \n",
            "\n",
            "f1 score with micro method : 87.87% \n",
            "\n",
            "f1 score with macro method : 87.89% \n",
            "\n",
            "f1 score with weighted method : 87.87% \n",
            "\n",
            "time for Normal Decison Tree : 115.74153780937195 Seconds \n"
          ]
        }
      ],
      "source": [
        "start_decion_tree_time = time.time()\n",
        "# Map Collection for Tree's Accuracy \n",
        "f1_score_trees = dict()\n",
        "\n",
        "# Normal Decison Tree \n",
        "empurty_algo=['entropy'  , 'gini']\n",
        "average_methods = ['micro','macro','weighted'] \n",
        "\n",
        "\n",
        "# Fitting\n",
        "for empurty in empurty_algo : \n",
        " print(f\"Default Decision Tree using {empurty} criterion \\n\")\n",
        " for method in average_methods:\n",
        "  classifier_decision_tree=\tDecisionTreeClassifier(criterion=empurty)\n",
        "  classifier_decision_tree.fit(X_train, y_train)\n",
        "  y_pred = classifier_decision_tree.predict(X_test) \n",
        "  Precision,Recall,F1_score,_\t=precision_recall_fscore_support(y_test, y_pred, average=method)\n",
        "  f1_score_trees[f'Decision_Tree_{method}_{empurty}' ] = round(F1_score*100 , 2 )\n",
        "  print(f\"f1 score with {method} method : {round(F1_score*100 , 2 )}% \\n\")\n",
        "\n",
        "  \n",
        "end_decion_tree_time = time.time()\n",
        "\n",
        "\n",
        "#time\n",
        "print (f'time for Normal Decison Tree : {end_decion_tree_time-start_decion_tree_time} Seconds ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PefdBHDMghja"
      },
      "source": [
        "<H2> Fitting Data with Random Forest Ensemble Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNvNhP6Qh_t1",
        "outputId": "8b4db423-a97f-4227-aee3-2b619a3afad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "f1 score with Random Forest Classifier by micro  : 95.03% \n",
            "\n",
            "\n",
            "f1 score with Random Forest Classifier by macro  : 94.97% \n",
            "\n",
            "\n",
            "f1 score with Random Forest Classifier by weighted  : 95.03% \n",
            "\n",
            "time for Random Forest Tree : 3.982607126235962 Seconds \n"
          ]
        }
      ],
      "source": [
        "start_rf_tree = time.time()\n",
        "\n",
        "# Random Forrest Algorithm - Ensemble Tree\n",
        "classifier_rf =\tRandomForestClassifier(n_estimators\t=10, random_state=11) \n",
        "classifier_rf.fit(X_train, y_train)\n",
        "y_pred = classifier_rf.predict(X_test) \n",
        "\n",
        "end_rf_tree = time.time()\n",
        "\n",
        "\n",
        "# Get F1 Accuracy\n",
        "for method in average_methods:\n",
        "\n",
        " Precision,Recall,F1_score,_\t=precision_recall_fscore_support(y_test, y_pred, average=method)\n",
        " f1_score_trees[f'rf_{method}' ] = round(F1_score*100 , 2 )\n",
        " print(f\"\\nf1 score with Random Forest Classifier by {method}  : {round(F1_score*100 , 2 )}% \\n\")\n",
        "\n",
        "\n",
        "# time\n",
        "print (f'time for Random Forest Tree : {end_rf_tree-start_rf_tree} Seconds ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI_E0oZ1-TJh"
      },
      "source": [
        "<H2> Bagging Ensemble Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA0EGhXeJtjt",
        "outputId": "778e8db0-6955-4d18-e053-04877336eed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score with Bagging Classifier by micro  : 93.66%\n",
            "f1 score with Bagging Classifier by macro  : 93.58%\n",
            "f1 score with Bagging Classifier by weighted  : 93.65%\n",
            "time for Bagging Ensemble Tree : 120.6460177898407 Seconds \n"
          ]
        }
      ],
      "source": [
        "start_bagging_tree = time.time()\n",
        "\n",
        "# Bagging Algorithm - Ensemble Tree\n",
        " \n",
        "classifier_bagging =\tBaggingClassifier(n_estimators\t=10, random_state=11) \n",
        "classifier_bagging.fit(X_train, y_train)\n",
        "y_pred = classifier_bagging.predict(X_test) \n",
        "\n",
        "end_bagging_tree = time.time()\n",
        "\n",
        "\n",
        "\n",
        "# Get F1 Accuracy\n",
        "for method in average_methods:\n",
        " Precision,Recall,F1_score,_\t=precision_recall_fscore_support(y_test, y_pred, average=method)\n",
        " f1_score_trees[f'bagging_{method}' ] = round(F1_score*100 , 2 )\n",
        " print(f\"f1 score with Bagging Classifier by {method}  : {round(F1_score*100 , 2 )}%\")\n",
        "\n",
        "# time\n",
        "print (f'time for Bagging Ensemble Tree : {end_bagging_tree-start_bagging_tree} Seconds ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S-QoHub-xN2"
      },
      "source": [
        "<H2> Adaptive Boosting Ensemble Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwGmW_-fPp1L",
        "outputId": "3e35a219-a832-4f2f-97e2-a37484eb464b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score with Adaptive Boosting Classifier by micro  : 87.61%\n",
            "f1 score with Adaptive Boosting Classifier by macro  : 87.46%\n",
            "f1 score with Adaptive Boosting Classifier by weighted  : 87.61%\n",
            "time for Ada Boosting Ensemble Tree : 19.034960508346558 Seconds \n"
          ]
        }
      ],
      "source": [
        "start_ada_tree = time.time()\n",
        "# Adaptive Boosting Algorithm - Ensemble Tree\n",
        "\n",
        "classifier_Ada = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(), n_estimators=10,random_state=11)\n",
        "classifier_Ada.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier_Ada.predict(X_test) \n",
        "\n",
        "end_ada_tree = time.time()\n",
        "\n",
        "\n",
        "# Get F1 Accuracy\n",
        "for method in average_methods:\n",
        " Precision,Recall,F1_score,_\t=precision_recall_fscore_support(y_test, y_pred, average=method)\n",
        " f1_score_trees[f'ada_boosting_{method}' ] = round(F1_score*100 , 2 )\n",
        " print(f\"f1 score with Adaptive Boosting Classifier by {method}  : {round(F1_score*100 , 2 )}%\")\n",
        "\n",
        "# time \n",
        "print (f'time for Ada Boosting Ensemble Tree : {end_ada_tree-start_ada_tree} Seconds ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqVyXdq5_r7v"
      },
      "source": [
        "<H2> XGradient Boosting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS7aVjEPKfiB",
        "outputId": "bb73057b-abba-4834-9124-3b27ab0f8de1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score with XG Boosting Classifier by micro  : 83.93%\n",
            "f1 score with XG Boosting Classifier by macro  : 83.74%\n",
            "f1 score with XG Boosting Classifier by weighted  : 83.91%\n",
            "time for XGB Boosting Ensemble Tree : 70.83134603500366 Seconds \n"
          ]
        }
      ],
      "source": [
        "start_xgb_tree = time.time()\n",
        "# XGradient Boosting Algorithm - Ensemble Tree\n",
        "\n",
        "classifier_xgb = XGBClassifier(n_estimators=10,random_state=11) \n",
        "classifier_xgb.fit(X_train, y_train)\n",
        "y_pred = classifier_xgb.predict(X_test) \n",
        "end_xgb_tree = time.time()\n",
        "\n",
        "\n",
        "# Get F1 Accuracy\n",
        "for method in average_methods:\n",
        " Precision,Recall,F1_score,_\t=precision_recall_fscore_support(y_test, y_pred, average=method)\n",
        " f1_score_trees[f'Xgb_boosting_{method}' ] = round(F1_score*100 , 2 )\n",
        " print(f\"f1 score with XG Boosting Classifier by {method}  : {round(F1_score*100 , 2 )}%\")\n",
        "\n",
        "\n",
        "# time \n",
        "print (f'time for XGB Boosting Ensemble Tree : {end_xgb_tree-start_xgb_tree} Seconds ')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJ7vafGCAfRQ"
      },
      "source": [
        "<H2> Light Gradient Boosting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6MAJUKULQG1",
        "outputId": "9d05980f-31e6-407f-b561-1be41e70b4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score with Light G Boosting Classifier  : 92.38%\n",
            "f1 score with Light G Boosting Classifier  : 92.29%\n",
            "f1 score with Light G Boosting Classifier  : 92.37%\n",
            "time for LGB Boosting Ensemble Tree : 22.430660724639893 Seconds \n"
          ]
        }
      ],
      "source": [
        "start_lgb_tree = time.time()\n",
        "# Light Gradient Boosting Algorithm - Ensemble Tree\n",
        "\n",
        "classifier_lgb = LGBMClassifier(n_estimators=10,random_state=11) \n",
        "classifier_lgb.fit(X_train, y_train)\n",
        "y_pred = classifier_lgb.predict(X_test) \n",
        "end_lgb_tree = time.time()\n",
        "\n",
        "\n",
        "# Get F1 Accuracy\n",
        "for method in average_methods:\n",
        " Precision,Recall,F1_score,_\t=precision_recall_fscore_support(y_test, y_pred, average=method)\n",
        " f1_score_trees[f'Lgb_boosting_{method}' ] = round(F1_score*100 , 2 )\n",
        " print(f\"f1 score with Light G Boosting Classifier  : {round(F1_score*100 , 2 )}%\")\n",
        "\n",
        "\n",
        "# time \n",
        "print (f'time for LGB Boosting Ensemble Tree : {end_lgb_tree-start_lgb_tree} Seconds ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fhybP8q9Kef",
        "outputId": "1f3ed006-f46d-44ad-bae2-cf6d62447795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision_Tree_micro_entropy : 88.66% \n",
            "\n",
            "Decision_Tree_macro_entropy : 88.14% \n",
            "\n",
            "Decision_Tree_weighted_entropy : 88.66% \n",
            "\n",
            "Decision_Tree_micro_gini : 87.87% \n",
            "\n",
            "Decision_Tree_macro_gini : 87.89% \n",
            "\n",
            "Decision_Tree_weighted_gini : 87.87% \n",
            "\n",
            "rf_micro : 95.03% \n",
            "\n",
            "rf_macro : 94.97% \n",
            "\n",
            "rf_weighted : 95.03% \n",
            "\n",
            "bagging_micro : 93.66% \n",
            "\n",
            "bagging_macro : 93.58% \n",
            "\n",
            "bagging_weighted : 93.65% \n",
            "\n",
            "ada_boosting_micro : 87.61% \n",
            "\n",
            "ada_boosting_macro : 87.46% \n",
            "\n",
            "ada_boosting_weighted : 87.61% \n",
            "\n",
            "Xgb_boosting_micro : 83.93% \n",
            "\n",
            "Xgb_boosting_macro : 83.74% \n",
            "\n",
            "Xgb_boosting_weighted : 83.91% \n",
            "\n",
            "Lgb_boosting_micro : 92.38% \n",
            "\n",
            "Lgb_boosting_macro : 92.29% \n",
            "\n",
            "Lgb_boosting_weighted : 92.37% \n",
            "\n"
          ]
        }
      ],
      "source": [
        " # Checking All Trees Accuracies\n",
        "for tree in f1_score_trees.keys():\n",
        "  print(f'{tree} : { f1_score_trees[tree]}% \\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwLvbab3SPb7"
      },
      "outputs": [],
      "source": [
        "# As the Random Forest Ensemble Tree is the optimal with 95% F1 Score \n",
        "# we will tune its params tell get its best "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_UHe7-xSdnN"
      },
      "source": [
        "<H2> Tunning Paramters for Improving Random Forest Ensemble Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLGQeFxns0gW",
        "outputId": "6b71b08f-dd68-4252-86f8-618bd66f93ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40 Estimators \n",
            "\n",
            "Score is 96.48% by Avg Method : micro\n",
            "\n",
            "Score is 96.44% by Avg Method : macro\n",
            "\n",
            "Score is 96.48% by Avg Method : weighted\n",
            "\n",
            "90 Estimators \n",
            "\n",
            "Score is 96.97% by Avg Method : micro\n",
            "\n",
            "Score is 96.94% by Avg Method : macro\n",
            "\n",
            "Score is 96.97% by Avg Method : weighted\n",
            "\n",
            "140 Estimators \n",
            "\n",
            "Score is 96.92% by Avg Method : micro\n",
            "\n",
            "Score is 96.9% by Avg Method : macro\n",
            "\n",
            "Score is 96.92% by Avg Method : weighted\n",
            "\n",
            "190 Estimators \n",
            "\n",
            "Score is 96.96% by Avg Method : micro\n",
            "\n",
            "Score is 96.94% by Avg Method : macro\n",
            "\n",
            "Score is 96.96% by Avg Method : weighted\n",
            "\n",
            "240 Estimators \n",
            "\n",
            "Score is 97.05% by Avg Method : micro\n",
            "\n",
            "Score is 97.03% by Avg Method : macro\n",
            "\n",
            "Score is 97.05% by Avg Method : weighted\n",
            "\n",
            "290 Estimators \n",
            "\n",
            "Score is 97.07% by Avg Method : micro\n",
            "\n",
            "Score is 97.05% by Avg Method : macro\n",
            "\n",
            "Score is 97.07% by Avg Method : weighted\n",
            "\n",
            "340 Estimators \n",
            "\n",
            "Score is 97.03% by Avg Method : micro\n",
            "\n",
            "Score is 97.0% by Avg Method : macro\n",
            "\n",
            "Score is 97.03% by Avg Method : weighted\n",
            "\n",
            "390 Estimators \n",
            "\n",
            "Score is 97.14% by Avg Method : micro\n",
            "\n",
            "Score is 97.12% by Avg Method : macro\n",
            "\n",
            "Score is 97.14% by Avg Method : weighted\n",
            "\n",
            "440 Estimators \n",
            "\n",
            "Score is 97.11% by Avg Method : micro\n",
            "\n",
            "Score is 97.09% by Avg Method : macro\n",
            "\n",
            "Score is 97.11% by Avg Method : weighted\n",
            "\n",
            "490 Estimators \n",
            "\n",
            "Score is 97.1% by Avg Method : micro\n",
            "\n",
            "Score is 97.08% by Avg Method : macro\n",
            "\n",
            "Score is 97.1% by Avg Method : weighted\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get F1 Accuracy\n",
        "for est in range(round(len(X_test )*0.004) ,round(len(X_test)*0.05)  , 50):\n",
        " classifier_rf =\tRandomForestClassifier(n_estimators\t=est, random_state=11 ,criterion = 'gini'  ) \n",
        "\n",
        " classifier_rf.fit(X_train, y_train)\n",
        " y_pred2 = classifier_rf.predict(X_test) \n",
        "\n",
        " print(f'{est} Estimators \\n')\n",
        " for method in average_methods:\n",
        "  _,_,F1_score,_\t=precision_recall_fscore_support(y_test, y_pred2,average=method)\n",
        "  print(f'Score is {round(F1_score*100,2)}% by Avg Method : {method}\\n' )\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Observation \n",
        "# By Tunning Random Forest Estimators more than 200 it gives F1 Accuracy more than 97% "
      ],
      "metadata": {
        "id": "wYWygH5VtRSB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}