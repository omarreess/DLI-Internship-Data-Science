{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOl+TH3Ov5lfa+zSTGVeXl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omarreess/DLI-Internship-Data-Science/blob/main/Assignment%208%20-%20Decision%20Tree%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<H2><center> Decision Tree Model with Ensebmle Trees"
      ],
      "metadata": {
        "id": "4FVeHI75fmIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<H2> Importing"
      ],
      "metadata": {
        "id": "Pvo-kcxNFwM2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n-2eHIaFgxX"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from keras.datasets import mnist\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support \n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "import sklearn\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import StackingClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<H2> Reshaping Data"
      ],
      "metadata": {
        "id": "MJJbTsq3iWrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0],-1) / 255.0 \n",
        "X_test = X_test.reshape(X_test.shape[0],-1) / 255.0"
      ],
      "metadata": {
        "id": "oS1mrO_QF6mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<H2> Fitting Data with Decision Tree Classifier"
      ],
      "metadata": {
        "id": "tFWfjYrXin5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier=\tDecisionTreeClassifier(criterion='gini')\n",
        "\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test) \n",
        "print(f'Prediected : {y_pred[0]} Actual : { y_test[0]}')\n",
        "\n",
        "average_methods = ['micro','macro','weighted'] \n",
        "for method in average_methods:\n",
        " Precision,Recall,F1_score,_\t=precision_recall_fscore_support(y_test, y_pred, average=method)\n",
        " print(f\"f1 score with {method} method : {round(F1_score*100 , 2 )}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9lUG2bHGFd2",
        "outputId": "9c9e5e0e-27dd-4511-e604-7a65ae02d44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediected : 7 Actual : 7\n",
            "f1 score with micro method : 87.5%\n",
            "f1 score with macro method : 87.33%\n",
            "f1 score with weighted method : 87.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<H2> Try Different Ensemble Tree for more Accuracy"
      ],
      "metadata": {
        "id": "PefdBHDMghja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking Algorithm - Ensmble Tree\n",
        "models = [('lr',LogisticRegression()),('svm',SVC())]\n",
        "\n",
        "stacking = StackingClassifier(estimators=models)\n",
        "stacking.fit(X_train, y_train)\n",
        "y_pred = stacking.predict(X_test) \n",
        "\n",
        "# Get F1 Accuracy\n",
        "Precision,Recall,F1_score,_\t=precision_recall_fscore_support(y_test, y_pred, average=method)\n",
        "print(f\"f1 score with Stacking Classifier  : {round(F1_score*100 , 2 )}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIF-iq0OKFwi",
        "outputId": "1b8f3bfd-158a-4761-9e35-3f38f68878be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score with Stacking Classifier  : 97.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"f1 score with Stacking Classifier  : {round(F1_score*100 , 2 )}%\")\n",
        "\n",
        "# As it give us around 97% F1 Score more than Normal Desiicon Tree Classifer "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNvNhP6Qh_t1",
        "outputId": "49c55146-7fa7-49b7-9094-3a30d32aec78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score with Stacking Classifier  : 97.88%\n"
          ]
        }
      ]
    }
  ]
}